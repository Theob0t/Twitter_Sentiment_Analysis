{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Data-pre-processing\" data-toc-modified-id=\"Data-pre-processing-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Data pre-processing</a></span></li><li><span><a href=\"#Building-the-word2vec-model\" data-toc-modified-id=\"Building-the-word2vec-model-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Building the word2vec model</a></span></li><li><span><a href=\"#Building-a-sentiment-classifier\" data-toc-modified-id=\"Building-a-sentiment-classifier-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Building a sentiment classifier</a></span></li><li><span><a href=\"#Testing\" data-toc-modified-id=\"Testing-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Testing</a></span></li><li><span><a href=\"#Scrapping-Twitter\" data-toc-modified-id=\"Scrapping-Twitter-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Scrapping Twitter</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentimental Analysis - BUILDING THE MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\theo0\\anaconda3\\envs\\keras_env\\lib\\site-packages\\tqdm\\std.py:668: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd # provide sql-like data manipulation tools. very handy.\n",
    "\n",
    "import numpy as np # high dimensional vector computing library.\n",
    "\n",
    "from string import punctuation\n",
    "from random import shuffle\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"progress-bar\")\n",
    "\n",
    "import gensim\n",
    "from gensim.models.word2vec import Word2Vec # the word2vec model gensim class\n",
    "LabeledSentence = gensim.models.doc2vec.LabeledSentence # we'll talk about this down below\n",
    "TaggedDocument = gensim.models.doc2vec.TaggedDocument\n",
    "\n",
    "from nltk.tokenize import TweetTokenizer # a tweet tokenizer from nltk.\n",
    "tokenizer = TweetTokenizer()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#Sources:\n",
    "#https://www.ahmedbesbes.com/blog/sentiment-analysis-with-keras-and-word-2-vec\n",
    "#https://towardsdatascience.com/sentiment-analysis-for-text-with-deep-learning-2f0a0c6472b5\n",
    "#https://www.youtube.com/watch?v=mI23bDF0VRI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a function that loads the dataset and extracts the two columns we need:\n",
    "\n",
    "The sentiment: a binary (0/1) variable\n",
    "\n",
    "The text of the tweet: string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset loaded with shape (1048575, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sentiment                                      SentimentText\n",
       "0          0  is upset that he can't update his Facebook by ...\n",
       "1          0  @Kenichan I dived many times for the ball. Man...\n",
       "2          0    my whole body feels itchy and like its on fire \n",
       "3          0  @nationwideclass no, it's not behaving at all....\n",
       "4          0                      @Kwesidei not the whole crew "
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ingest():\n",
    "    data = pd.read_csv('data/training.csv', engine='python')\n",
    "    data = data[data.Sentiment.isnull() == False]\n",
    "    data['Sentiment'] = data['Sentiment'].map(int)\n",
    "    data = data[data['SentimentText'].isnull() == False]\n",
    "    data.reset_index(inplace=True)\n",
    "    data.drop('index', axis=1, inplace=True)\n",
    "    print('dataset loaded with shape', data.shape)    \n",
    "    return data\n",
    "\n",
    "data = ingest()\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The format of the SentimenText is not useful. It needs to be tokenized and cleaned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(tweet):\n",
    "    tweet = tweet.lower()\n",
    "    tweet = ' '.join([ t for t in tweet.split() if not t.startswith(('@','#','http')) ])\n",
    "    #print(tweet)\n",
    "    tokens = tokenizer.tokenize(tweet)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data['tokens'] = [tokenize(data.SentimentText[i]) for i in range(len(data.SentimentText))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Sentiment = data.Sentiment.replace(4,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentText</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>[is, upset, that, he, can't, update, his, face...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>[i, dived, many, times, for, the, ball, ., man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>[my, whole, body, feels, itchy, and, like, its...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>[no, ,, it's, not, behaving, at, all, ., i'm, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "      <td>[not, the, whole, crew]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048570</th>\n",
       "      <td>1</td>\n",
       "      <td>My GrandMa is making Dinenr with my Mum</td>\n",
       "      <td>[my, grandma, is, making, dinenr, with, my, mum]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048571</th>\n",
       "      <td>1</td>\n",
       "      <td>Mid-morning snack time... A bowl of cheese noo...</td>\n",
       "      <td>[mid-morning, snack, time, ..., a, bowl, of, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048572</th>\n",
       "      <td>1</td>\n",
       "      <td>@ShaDeLa same here  say it like from the Termi...</td>\n",
       "      <td>[same, here, say, it, like, from, the, termini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048573</th>\n",
       "      <td>1</td>\n",
       "      <td>@DestinyHope92 im great thaanks  wbuu?</td>\n",
       "      <td>[im, great, thaanks, wbuu, ?]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048574</th>\n",
       "      <td>1</td>\n",
       "      <td>cant wait til her date this weekend</td>\n",
       "      <td>[cant, wait, til, her, date, this, weekend]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1048575 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Sentiment                                      SentimentText  \\\n",
       "0                0  is upset that he can't update his Facebook by ...   \n",
       "1                0  @Kenichan I dived many times for the ball. Man...   \n",
       "2                0    my whole body feels itchy and like its on fire    \n",
       "3                0  @nationwideclass no, it's not behaving at all....   \n",
       "4                0                      @Kwesidei not the whole crew    \n",
       "...            ...                                                ...   \n",
       "1048570          1           My GrandMa is making Dinenr with my Mum    \n",
       "1048571          1  Mid-morning snack time... A bowl of cheese noo...   \n",
       "1048572          1  @ShaDeLa same here  say it like from the Termi...   \n",
       "1048573          1             @DestinyHope92 im great thaanks  wbuu?   \n",
       "1048574          1               cant wait til her date this weekend    \n",
       "\n",
       "                                                    tokens  \n",
       "0        [is, upset, that, he, can't, update, his, face...  \n",
       "1        [i, dived, many, times, for, the, ball, ., man...  \n",
       "2        [my, whole, body, feels, itchy, and, like, its...  \n",
       "3        [no, ,, it's, not, behaving, at, all, ., i'm, ...  \n",
       "4                                  [not, the, whole, crew]  \n",
       "...                                                    ...  \n",
       "1048570   [my, grandma, is, making, dinenr, with, my, mum]  \n",
       "1048571  [mid-morning, snack, time, ..., a, bowl, of, c...  \n",
       "1048572  [same, here, say, it, like, from, the, termini...  \n",
       "1048573                      [im, great, thaanks, wbuu, ?]  \n",
       "1048574        [cant, wait, til, her, date, this, weekend]  \n",
       "\n",
       "[1048575 rows x 3 columns]"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\theo0\\anaconda3\\envs\\keras_env\\lib\\site-packages\\pandas\\core\\frame.py:4164: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "def postprocess(data, n=1000000):\n",
    "    data = data.head(n)\n",
    "    data.reset_index(inplace=True)\n",
    "    data.drop('index', inplace=True, axis=1)\n",
    "    return data\n",
    "\n",
    "data_ = postprocess(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_.to_csv('data/train_tokens.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the word2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(np.array(data_.tokens),\n",
    "                                                    np.array(data_.Sentiment), test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before feeding lists of tokens into the word2vec model, we must turn them into LabeledSentence objects beforehand.\n",
    "(LabeledSentence Objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]C:\\Users\\theo0\\anaconda3\\envs\\keras_env\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `LabeledSentence` (Class will be removed in 4.0.0, use TaggedDocument instead).\n",
      "  \"\"\"\n",
      "800000it [00:08, 97418.33it/s] \n",
      "200000it [00:00, 337817.83it/s]\n"
     ]
    }
   ],
   "source": [
    "def labelizeTweets(tweets, label_type):\n",
    "    labelized = []\n",
    "    for i,v in tqdm(enumerate(tweets)):\n",
    "        label = '%s_%s'%(label_type,i)\n",
    "        labelized.append(LabeledSentence(v, [label]))\n",
    "    return labelized\n",
    "\n",
    "x_train = labelizeTweets(x_train, 'TRAIN')\n",
    "x_test = labelizeTweets(x_test, 'TEST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabeledSentence(words=['i', 'wish', 'i', 'was', 'going', ',', 'proper', 'love', 'go', ':', 'audio', '<3'], tags=['TRAIN_0'])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to build the word2vec model from x_train i.e. the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the model is initialized with the dimension of the vector space (we set it to 200) and \n",
    "#min_count (a threshold for filtering words that appear less)\n",
    "n_dim = 200\n",
    "tweet_w2v = Word2Vec(size=n_dim, min_count=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 800000/800000 [00:00<00:00, 2040841.36it/s]\n"
     ]
    }
   ],
   "source": [
    "# vocabulary is created.\n",
    "tweet_w2v.build_vocab([x.words for x in tqdm(x_train)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 800000/800000 [00:00<00:00, 2105291.58it/s]\n",
      "C:\\Users\\theo0\\anaconda3\\envs\\keras_env\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(43065191, 59803780)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the model is trained i.e. its weights are updated.\n",
    "tweet_w2v.train([x.words for x in tqdm(x_train)],total_examples=tweet_w2v.corpus_count, epochs=tweet_w2v.iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_w2v.save(\"models/word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\theo0\\anaconda3\\envs\\keras_env\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('thumb', 0.8844152092933655),\n",
       " ('toe', 0.8621228337287903),\n",
       " ('tongue', 0.8546328544616699),\n",
       " ('foot', 0.8509114980697632),\n",
       " ('lip', 0.8447337746620178),\n",
       " ('leg', 0.8360134959220886),\n",
       " ('elbow', 0.8356807231903076),\n",
       " ('arm', 0.8269048929214478),\n",
       " ('ankle', 0.8137351870536804),\n",
       " ('wrist', 0.7897714376449585)]"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_w2v.most_similar('finger')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a sentiment classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for now, we have a word2vec model that converts each word from the corpus into a high dimensional vector. \n",
    "\n",
    "In order to classify tweets, we have to turn them into vectors as well. \n",
    "\n",
    "Since we know the vector representation of each word composing a tweet, we have to \"combine\" these vectors together and get a new one that represents the tweet as a whole."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do that: \n",
    "\n",
    "Compute a weighted average where each weight gives the importance of the word with respect to the corpus. Such a weight could the tf-idf score. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Let's start by building a tf-idf matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tf-idf matrix ...\n",
      "vocab size : 23169\n"
     ]
    }
   ],
   "source": [
    "print('building tf-idf matrix ...')\n",
    "vectorizer = TfidfVectorizer(analyzer=lambda x: x, min_df=10)\n",
    "matrix = vectorizer.fit_transform([x.words for x in x_train])\n",
    "tfidf = dict(zip(vectorizer.get_feature_names(), vectorizer.idf_))\n",
    "print('vocab size :', len(tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(tfidf, open(\"models/tfidf.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Now let's define a function that, given a list of tweet tokens, creates an averaged tweet vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildWordVector(tokens, size):\n",
    "    vec = np.zeros(size).reshape((1, size))\n",
    "    count = 0.\n",
    "    for word in tokens:\n",
    "        try:\n",
    "            vec += tweet_w2v[word].reshape((1, size)) * tfidf[word]\n",
    "            count += 1.\n",
    "        except KeyError: # handling the case where the token is not\n",
    "                         # in the corpus. useful for testing.\n",
    "            continue\n",
    "            \n",
    "    #avoid 0 division\n",
    "    if count != 0:\n",
    "        vec /= count\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we convert xtrain and and xtest into list of vectors using this function. \n",
    "\n",
    "We also scale each column to have zero mean and unit standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]C:\\Users\\theo0\\anaconda3\\envs\\keras_env\\lib\\site-packages\\ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n",
      "800000it [01:49, 7274.59it/s]\n",
      "0it [00:00, ?it/s]C:\\Users\\theo0\\anaconda3\\envs\\keras_env\\lib\\site-packages\\ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n",
      "200000it [00:29, 6698.75it/s]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import scale\n",
    "\n",
    "train_vecs_w2v = np.concatenate([buildWordVector(z, n_dim) for z in tqdm(map(lambda x: x.words, x_train))])\n",
    "train_vecs_w2v = scale(train_vecs_w2v)\n",
    "\n",
    "test_vecs_w2v = np.concatenate([buildWordVector(z, n_dim) for z in tqdm(map(lambda x: x.words, x_test))])\n",
    "test_vecs_w2v = scale(test_vecs_w2v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should now be ready to feed these vectors into a neural network classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 560000 samples, validate on 240000 samples\n",
      "Epoch 1/9\n",
      "560000/560000 [==============================] - 24s 42us/step - loss: 0.3537 - accuracy: 0.8517 - val_loss: 0.3414 - val_accuracy: 0.8568\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.85681, saving model to best_model.h5\n",
      "Epoch 2/9\n",
      "560000/560000 [==============================] - 22s 39us/step - loss: 0.3382 - accuracy: 0.8579 - val_loss: 0.3386 - val_accuracy: 0.8584\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.85681 to 0.85842, saving model to best_model.h5\n",
      "Epoch 3/9\n",
      "560000/560000 [==============================] - 22s 39us/step - loss: 0.3343 - accuracy: 0.8597 - val_loss: 0.3361 - val_accuracy: 0.8589\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.85842 to 0.85893, saving model to best_model.h5\n",
      "Epoch 4/9\n",
      "560000/560000 [==============================] - 22s 39us/step - loss: 0.3317 - accuracy: 0.8610 - val_loss: 0.3356 - val_accuracy: 0.8592\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.85893 to 0.85924, saving model to best_model.h5\n",
      "Epoch 5/9\n",
      "560000/560000 [==============================] - 22s 39us/step - loss: 0.3300 - accuracy: 0.8614 - val_loss: 0.3358 - val_accuracy: 0.8594\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.85924 to 0.85943, saving model to best_model.h5\n",
      "Epoch 6/9\n",
      "560000/560000 [==============================] - 22s 40us/step - loss: 0.3286 - accuracy: 0.8621 - val_loss: 0.3360 - val_accuracy: 0.8584\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.85943\n",
      "Epoch 7/9\n",
      "560000/560000 [==============================] - 22s 39us/step - loss: 0.3275 - accuracy: 0.8624 - val_loss: 0.3344 - val_accuracy: 0.8608\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.85943 to 0.86080, saving model to best_model.h5\n",
      "Epoch 8/9\n",
      "560000/560000 [==============================] - 22s 39us/step - loss: 0.3266 - accuracy: 0.8628 - val_loss: 0.3341 - val_accuracy: 0.8607\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.86080\n",
      "Epoch 9/9\n",
      "560000/560000 [==============================] - 23s 40us/step - loss: 0.3258 - accuracy: 0.8631 - val_loss: 0.3358 - val_accuracy: 0.8593\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.86080\n"
     ]
    }
   ],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=200))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=200)\n",
    "mc = ModelCheckpoint('models/best_model.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
    "\n",
    "history = model.fit(train_vecs_w2v, y_train, epochs=9, batch_size=32, verbose=1, validation_split=0.3, callbacks=[es, mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# plot training history\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a saved model\n",
    "from keras.models import load_model\n",
    "saved_model = load_model('models/best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_pipeline(tweet):\n",
    "    '''\n",
    "    Transformation Pipeline of the input tweet.\n",
    "    STEP:\n",
    "    - Tokenize the tweet => ['i', 'love', 'you']\n",
    "    - Convert to LabeledSentence gensim object\n",
    "    - Build tweet vectorization (word2vec)\n",
    "    - Scale (zero mean and unit standard deviation)\n",
    "    \n",
    "    input:\n",
    "    raw tweet, string\n",
    "    output:\n",
    "    vectorized tweet, np.array (200,)\n",
    "    '''\n",
    "\n",
    "    trump_tweet_tokenized = tokenize(tweet)\n",
    "    \n",
    "    trump_tweet_labelized = TaggedDocument(trump_tweet_tokenized,'TEST')\n",
    "    \n",
    "    tweet_vec = np.concatenate(buildWordVector(trump_tweet_labelized.words, n_dim))\n",
    "    \n",
    "    tweet = [scale(tweet_vec)]\n",
    "    \n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_analysis(tweet, model):\n",
    "    \n",
    "    vect_tweet = tweet_pipeline(tweet)\n",
    "    \n",
    "    if (vect_tweet[0].ndim == 1):\n",
    "        vect_tweet[0] = np.array([vect_tweet[0]])\n",
    "    prediction = model.predict(vect_tweet[0])\n",
    "    \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\theo0\\anaconda3\\envs\\keras_env\\lib\\site-packages\\ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.71768564]], dtype=float32)"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_analysis('I love you', saved_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the model is trained, let's evaluate it on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(test_vecs_w2v, y_test, batch_size=128, verbose=2)\n",
    "print(score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_tweet_labelized.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\theo0\\anaconda3\\envs\\keras_env\\lib\\site-packages\\ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#raw tweet\n",
    "trump_tweet = 'The Radical Left Mayors &  Governors of Cities where this crazy violence is taking place have lost control of their “Movement”. It wasn’t supposed to be like this, but the Anarchists & Agitators got carried away and don’t listen anymore - even forced Slow Joe out of basement!'\n",
    "#tokenization of the tweet => ['i', 'love', 'you']\n",
    "trump_tweet_tokenized = tokenize(trump_tweet)\n",
    "#convert to LabeledSentence objects\n",
    "trump_tweet_labelized = TaggedDocument(trump_tweet_tokenized,'TEST')\n",
    "#build world vector\n",
    "tweet_vec = np.concatenate(buildWordVector(trump_tweet_labelized.words, n_dim))\n",
    "#scale\n",
    "tweet2 = [scale(tweet_vec)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02822554]], dtype=float32)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if (tweet2[0].ndim == 1):\n",
    "    tweet2[0] = np.array([tweet2[0]])\n",
    "model.predict(tweet2[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrapping Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Just watched what Biden had to say. To me, he’s blaming the Police far more than he’s blaming the Rioters, Anarchists, Agitators, and Looters, which he could never blame or he would lose the Radical Left Bernie supports!\n"
     ]
    }
   ],
   "source": [
    "import GetOldTweets3 as got\n",
    "def scrapping_twitter(username='realDonaldTrump'):\n",
    "    count = 2\n",
    "\n",
    "    tweetCriteria = got.manager.TweetCriteria().setUsername(username)\\\n",
    "                                               .setMaxTweets(count)\n",
    "    tweet = got.manager.TweetManager.getTweets(tweetCriteria)[0]\n",
    "    \n",
    "    return tweet.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\theo0\\anaconda3\\envs\\keras_env\\lib\\site-packages\\ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.13973978]], dtype=float32)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_analysis(tweet.text, saved_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras_env",
   "language": "python",
   "name": "keras_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
